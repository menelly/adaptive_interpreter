#!/usr/bin/env python3
"""
Offline evaluation of "unsquamping" DN plausibility weight effects using existing discovery_results_*.tsv

- Reads TSVs in results/ generated by the cascade pipeline
- Parses the embedded full_cascade_result dict for per-row details
- Reconstructs an "unsquamped" DN score by dividing out the plausibility weight for the recorded gene_family
- Recomputes final score using:
    * max of mechanism scores (DN_unsquamped, LOF, GOF)
    * OR synergy between the top two mechanisms (DN/LOF/GOF) via calculate_synergy_score_v2
    * Applies the damped conservation multiplier recorded for that row (if present)
- Classifies using VariantClassifier defaults (global thresholds)
- Emits per-variant comparison and per-gene summary, plus an aggregate summary

This is read-only and does not modify existing results. Outputs:
- results/unsquamp_eval.tsv (per-row comparison)
- results/unsquamp_summary.tsv (per-gene deltas)
- Console summary
"""

import csv
import ast
import re
import sys
from pathlib import Path
from typing import Dict, Any, List, Tuple

# Import from the main (non-FIXED) tree only, per Ren's request
from AdaptiveInterpreter.utils.plausibility_filter import PATHOGENICITY_RULES
from AdaptiveInterpreter.utils.ensemble_scores import calculate_synergy_score_v2, get_gene_family
from AdaptiveInterpreter.utils.score_aggregator import apply_damped_conservation_scaling
from AdaptiveInterpreter.utils.classifier import VariantClassifier

RESULTS_DIR = Path("results")
OUT_PER_ROW = RESULTS_DIR / "unsquamp_eval.tsv"
OUT_SUMMARY = RESULTS_DIR / "unsquamp_summary.tsv"


CLINVAR_MAP = {
    # Normalize ClinVar-ish strings to ACMG buckets used by our classifier
    "pathogenic": "P",
    "likely_pathogenic": "LP",
    "vus": "VUS",
    "uncertain_significance": "VUS",
    "likely_benign": "LB",
    "benign": "B",
    # common variants
    "other": "VUS",
}


def norm_clinvar(val: str) -> str:
    if not val:
        return "VUS"
    key = val.strip().lower().replace("-", "_")
    return CLINVAR_MAP.get(key, "VUS")


def infer_dn_unsquamped(dn_filtered: float, gene_family: str) -> Tuple[float, float]:
    """Return (dn_unsquamped, weight_used). If no rule for family, use 1.0.
    We assume plausibility filter applied: dn_filtered = dn_raw * weight.
    So dn_unsquamped â‰ˆ min(dn_filtered / weight, 1.0).
    """
    fam = (gene_family or "GENERAL").upper()
    weights = PATHOGENICITY_RULES.get(fam, PATHOGENICITY_RULES.get("GENERAL", {"DN": 1.0}))
    w = float(weights.get("DN", 1.0))
    if w <= 0:
        return dn_filtered, w
    return min(dn_filtered / w, 1.0), w


def recompute_final_unsquamped(mech_scores: Dict[str, float], gene: str, conservation_mult: float) -> Tuple[float, bool, float]:
    """Compute final score with synergy consideration and conservation damping.
    Returns (final_score, synergy_used, synergy_score_before_damping).
    """
    # Best single mechanism
    best_single = max(mech_scores.values()) if mech_scores else 0.0

    # Try synergy between top two
    syn = calculate_synergy_score_v2(mech_scores, get_gene_family(gene))
    synergy_score = float(syn.get("synergy_score", 0.0))
    synergy_used = bool(syn.get("synergy_used", False)) and synergy_score > best_single

    base = max(best_single, synergy_score)
    final = apply_damped_conservation_scaling(base, conservation_mult or 1.0)
    # Clamp like aggregator does
    final = max(0.0, min(final, 5.0))
    return final, synergy_used, synergy_score


def analyze_file(path: Path, writer: csv.DictWriter, clf: VariantClassifier) -> Dict[str, int]:
    """Process one discovery_results_*.tsv and write per-row outputs. Return summary counts for this gene."""
    counts = {"N": 0, "UP": 0, "DOWN": 0, "SAME": 0, "AGREE_IMPROVE": 0, "AGREE_WORSE": 0}
    gene = path.stem.replace("discovery_results_", "")

    with path.open("r", newline="") as f:
        reader = csv.DictReader(f, delimiter="\t")
        for row in reader:
            counts["N"] += 1

            # Parse the embedded dict
            try:
                full = ast.literal_eval(row.get("full_cascade_result", "{}"))
            except Exception:
                full = {}

            # Skip non-missense/guarded rows
            analyzers = full.get("analyzers_run", []) or []
            if analyzers == ["SYNONYMOUS_GUARD"]:
                continue

            pf = full.get("plausibility_filtered_scores", full.get("scores", {})) or {}
            gene_family = full.get("gene_family") or row.get("gene_family") or "GENERAL"

            dn_f = float(pf.get("DN", 0.0))
            lof_f = float(pf.get("LOF", 0.0))
            gof_f = float(pf.get("GOF", 0.0))

            # Reconstruct an unsquamped DN
            dn_unsq, dn_weight = infer_dn_unsquamped(dn_f, gene_family)
            mech_unsq = {"DN": dn_unsq, "LOF": lof_f, "GOF": gof_f}

            # Conservation multiplier used originally (if recorded)
            cons_mult = float(full.get("conservation_multiplier_applied", 1.0) or 1.0)

            # Recompute final score/class
            unsq_final, syn_used, syn_score = recompute_final_unsquamped(mech_unsq, full.get("gene", gene), cons_mult)
            unsq_class = clf.interpret_score(unsq_final)

            # Current recorded cascade outcome
            orig_final = float(full.get("final_score", row.get("cascade_score") or 0.0) or 0.0)
            orig_class = full.get("final_classification", row.get("cascade_class") or "UNCLASSIFIED")

            # Simple change flag
            change = "SAME"
            thr_order = ["B", "LB", "VUS", "VUS-P", "LP", "P"]
            def rank(c: str) -> int:
                c = (c or "VUS").upper()
                return thr_order.index(c) if c in thr_order else thr_order.index("VUS")
            if rank(unsq_class) > rank(orig_class):
                change = "UP"
            elif rank(unsq_class) < rank(orig_class):
                change = "DOWN"
            counts[change] += 1

            # Rough agreement deltas versus ClinVar
            clin = norm_clinvar(row.get("clinvar_sig", ""))
            def agree(a: str, b: str) -> bool:
                # Exact match or near (LP~P, LB~B considered soft-agree)
                if a == b:
                    return True
                return (a, b) in [("LP", "P"), ("P", "LP"), ("LB", "B"), ("B", "LB")]
            was_agree = agree(orig_class, clin)
            now_agree = agree(unsq_class, clin)
            if now_agree and not was_agree:
                counts["AGREE_IMPROVE"] += 1
            elif was_agree and not now_agree:
                counts["AGREE_WORSE"] += 1

            writer.writerow({
                "gene": full.get("gene", gene),
                "variant": full.get("variant", row.get("hgvs_p", "")),
                "clinvar": clin,
                "family": gene_family,
                "dn_weight": dn_weight,
                "dn_filtered": dn_f,
                "dn_unsquamped": dn_unsq,
                "lof": lof_f,
                "gof": gof_f,
                "orig_final": orig_final,
                "orig_class": orig_class,
                "unsq_final": round(unsq_final, 6),
                "unsq_class": unsq_class,
                "change": change,
                "synergy_used": syn_used,
                "synergy_score": round(syn_score, 6),
                "conservation_mult": cons_mult,
                "source_file": path.name,
            })

    return counts


def main(argv: List[str]) -> int:
    tsvs = sorted(RESULTS_DIR.glob("discovery_results_*.tsv"))
    if not tsvs:
        print("[unsquamp] No discovery_results_*.tsv files found in results/")
        return 1

    OUT_PER_ROW.parent.mkdir(parents=True, exist_ok=True)

    # Prepare writers
    with OUT_PER_ROW.open("w", newline="") as per_row:
        cols = [
            "gene","variant","clinvar","family","dn_weight","dn_filtered","dn_unsquamped",
            "lof","gof","orig_final","orig_class","unsq_final","unsq_class","change",
            "synergy_used","synergy_score","conservation_mult","source_file"
        ]
        writer = csv.DictWriter(per_row, fieldnames=cols, delimiter='\t')
        writer.writeheader()

        clf = VariantClassifier()

        aggregate = {"N": 0, "UP": 0, "DOWN": 0, "SAME": 0, "AGREE_IMPROVE": 0, "AGREE_WORSE": 0}
        per_gene: Dict[str, Dict[str, int]] = {}

        for tsv in tsvs:
            gene = tsv.stem.replace("discovery_results_", "")
            print(f"[unsquamp] Processing {gene} <- {tsv}")
            counts = analyze_file(tsv, writer, clf)
            per_gene[gene] = counts
            for k, v in counts.items():
                aggregate[k] = aggregate.get(k, 0) + v

    # Write per-gene summary
    with OUT_SUMMARY.open("w", newline="") as fh:
        cols = ["gene","N","UP","DOWN","SAME","AGREE_IMPROVE","AGREE_WORSE"]
        w = csv.DictWriter(fh, fieldnames=cols, delimiter='\t')
        w.writeheader()
        for gene, c in sorted(per_gene.items()):
            row = {"gene": gene}
            row.update({k: c.get(k, 0) for k in cols if k != "gene"})
            w.writerow(row)

    # Console summary
    print("\n=== UNSQUAMP EVAL: Aggregate ===")
    for k in ["N","UP","DOWN","SAME","AGREE_IMPROVE","AGREE_WORSE"]:
        print(f"{k:>15}: {aggregate.get(k,0)}")

    print(f"\nPer-row output:   {OUT_PER_ROW}")
    print(f"Per-gene summary: {OUT_SUMMARY}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv[1:]))

